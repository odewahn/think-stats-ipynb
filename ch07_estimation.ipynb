{
  "metadata": {
    "name": "Estimation"
  },
  "nbformat": 3,
  "nbformat_minor": 0,
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading",
          "level": 1,
          "metadata": {
          },
          "source": "Estimation"
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "The Estimation Game"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Let’s play a game. I’ll think of a distribution, and you have to guess what it is. We’ll start out easy and work our way up."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "_I’m thinking of a distribution._ I’ll give you two hints; it’s a normal distribution, and here’s a random sample drawn from it:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "{−0.441, 1.774, −0.101, −1.138, 2.975, −2.138}"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "What do you think is the mean parameter, _μ_, of this distribution?"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "One choice is to use the sample mean to estimate _μ_. Up until now, we have used the symbol _μ_ for both the sample mean and the mean parameter, but now to distinguish them I will use x̄ for the sample mean. In this example, x̄ is 0.155, so it would be reasonable to guess _μ_ = 0.155."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "This process is called _estimation_, and the statistic we used (the sample mean) is called an _estimator_."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Using the sample mean to estimate _μ_ is so obvious that it is hard to imagine a reasonable alternative. But suppose we change the game by introducing outliers."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "_I’m thinking of a distribution._ It’s a normal distribution, and here’s a sample that was collected by an unreliable surveyor who occasionally puts the decimal point in the wrong place."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "{−0.441, 1.774, −0.101, −1.138, 2.975, −213.8}"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Now what’s your estimate of _μ_? If you use the sample mean, your guess is −35.12. Is that the best choice? What are the alternatives?"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "One option is to identify and discard outliers, then compute the sample mean of the rest. Another option is to use the median as an estimator."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Which estimator is the best depends on the circumstances (for example, whether there are outliers) and on what the goal is. Are you trying to minimize errors, or maximize your chance of getting the right answer?"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "If there are no outliers, the sample mean minimizes the _mean squared error_, or _MSE_. If we play the game many times, and each time compute the error x̄ − _μ_, the sample mean minimizes"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Where _m_ is the number of times you play the estimation game (not to be confused with _n_, which is the size of the sample used to compute x̄)."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Minimizing MSE is a nice property, but it’s not always the best strategy. For example, suppose we are estimating the distribution of wind speeds at a building site. If we guess too high, we might overbuild the structure, increasing its cost. But if we guess too low, the building might collapse. Because cost as a function of error is asymmetric, minimizing MSE is not the best strategy."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "As another example, suppose I roll three six-sided dice and ask you to predict the total. If you get it exactly right, you get a prize; otherwise, you get nothing. In this case, the value that minimizes MSE is 10.5, but that would be a terrible guess. For this game, you want an estimator that has the highest chance of being right, which is a _maximum likelihood estimator_, or _MLE_. If you pick 10 or 11, your chance of winning is 1 in 8, and that’s the best you can do."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Understanding Errors"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Before we go on, let’s clear up a common source of confusion. Properties like MSE and bias are long-term expectations based on many iterations of the estimation game."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "While you are playing the game, you don’t know the errors. That is, if I give you a sample and ask you to estimate a parameter, you can compute the value of the estimator, but you can’t compute the error. If you could, you wouldn’t need the estimator!"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The reason we talk about estimation error is to describe the behavior of different estimators in the long run. In this chapter we run experiments to examine those behaviors; these experiments are artificial in the sense that we know the actual values of the parameters, so we can compute errors. But when you work with real data, you don’t, so you can’t."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Now let’s get back to the game."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Exponential Distributions"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "_I’m thinking of a distribution._ It’s an exponential distribution, and here’s a sample:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "{5.384, 4.493, 19.198, 2.790, 6.122, 12.844}"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "What do you think is the parameter, _λ_, of this distribution?"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "In general, the mean of an exponential distribution is 1/_λ_, so working backwards, we might choose"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "![img-0052](figs/web/equations/img-0052.png) = 1 / x̄"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "It is common to use hat notation for estimators, so ![img-0052](figs/web/equations/img-0052.png) is an estimator of _λ_. And not just any estimator; it is also the MLE estimator. [15](ch07.html#idp1004432) So if you want to maximize your chance of guessing _λ_ exactly, ![img-0052](figs/web/equations/img-0052.png) is the way to go."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "But we know that x̄ is not robust in the presence of outliers, so we expect ![img-0052](figs/web/equations/img-0052.png) to have the same problem."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Maybe we can find an alternative based on the sample median. Remember that the median of an exponential distribution is log(2) / _λ_, so working backwards again, we can define an estimator"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "where _μ\\_\\_1/2_ is the sample median."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Glossary"
        }
      ],
      "metadata": {
      }
    }
  ]
}